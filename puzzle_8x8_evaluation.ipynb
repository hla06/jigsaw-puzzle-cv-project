{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c229064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 8Ã—8 Puzzle Evaluation Setup Complete\n"
     ]
    }
   ],
   "source": [
    "# Imports and Setup\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import json\n",
    "from typing import List, Dict\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Reload modules\n",
    "import importlib\n",
    "import exhaustive_solver\n",
    "import edge_matching\n",
    "import hierarchical_solver\n",
    "importlib.reload(edge_matching)\n",
    "importlib.reload(exhaustive_solver)\n",
    "importlib.reload(hierarchical_solver)\n",
    "\n",
    "from puzzle_utils import create_puzzle_pieces, assemble_puzzle, PuzzlePiece, get_complementary_edge\n",
    "from edge_matching import build_compatibility_matrix\n",
    "from validation import compute_accuracy_metrics, compute_piece_placement_accuracy\n",
    "from hierarchical_solver import hierarchical_solve\n",
    "\n",
    "# Paths\n",
    "PROJECT_ROOT = Path(\".\")\n",
    "DATASET_ROOT = PROJECT_ROOT / \"Jigsaw Puzzle Dataset\" / \"Gravity Falls\"\n",
    "OUTPUT_ROOT = PROJECT_ROOT / \"processed_images\"\n",
    "ENHANCED_DIR = OUTPUT_ROOT / \"enhanced\"\n",
    "MASK_DIR = OUTPUT_ROOT / \"masks\"\n",
    "CORRECT_DIR = DATASET_ROOT / \"correct\"\n",
    "ASSEMBLED_DIR = OUTPUT_ROOT / \"assembled_8x8\"\n",
    "RESULTS_DIR = PROJECT_ROOT / \"results\"\n",
    "\n",
    "ASSEMBLED_DIR.mkdir(exist_ok=True, parents=True)\n",
    "RESULTS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "print(\"âœ… 8Ã—8 Puzzle Evaluation Setup Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cf14e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Beam search helper defined\n"
     ]
    }
   ],
   "source": [
    "# Helper: Greedy Assembly with Beam Search\n",
    "def greedy_assemble_with_beam(pieces: List[PuzzlePiece], compatibility_matrix: np.ndarray, \n",
    "                               grid_size: int, beam_width: int = 7, verbose: bool = False) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Beam search assembly for quadrants.\n",
    "    \"\"\"\n",
    "    n_pieces = len(pieces)\n",
    "    edge_names = ['top', 'right', 'bottom', 'left']\n",
    "    \n",
    "    # Initialize\n",
    "    initial_arrangement = np.full((grid_size, grid_size), -1, dtype=int)\n",
    "    initial_arrangement[0, 0] = 0\n",
    "    beam = [(initial_arrangement.copy(), {0}, 0.0)]\n",
    "    \n",
    "    # Fill positions\n",
    "    for step in range(1, n_pieces):\n",
    "        new_candidates = []\n",
    "        \n",
    "        for arrangement, placed, cumulative_score in beam:\n",
    "            # Find empty positions with neighbors\n",
    "            candidate_positions = []\n",
    "            \n",
    "            for row in range(grid_size):\n",
    "                for col in range(grid_size):\n",
    "                    if arrangement[row, col] != -1:\n",
    "                        continue\n",
    "                    \n",
    "                    neighbors = []\n",
    "                    if row > 0 and arrangement[row-1, col] != -1:\n",
    "                        neighbors.append((arrangement[row-1, col], 'top'))\n",
    "                    if col > 0 and arrangement[row, col-1] != -1:\n",
    "                        neighbors.append((arrangement[row, col-1], 'left'))\n",
    "                    if row < grid_size-1 and arrangement[row+1, col] != -1:\n",
    "                        neighbors.append((arrangement[row+1, col], 'bottom'))\n",
    "                    if col < grid_size-1 and arrangement[row, col+1] != -1:\n",
    "                        neighbors.append((arrangement[row, col+1], 'right'))\n",
    "                    \n",
    "                    if neighbors:\n",
    "                        candidate_positions.append((row, col, neighbors))\n",
    "            \n",
    "            if not candidate_positions:\n",
    "                continue\n",
    "            \n",
    "            candidate_positions.sort(key=lambda x: len(x[2]), reverse=True)\n",
    "            row, col, neighbors = candidate_positions[0]\n",
    "            \n",
    "            # Score unplaced pieces\n",
    "            piece_scores = []\n",
    "            for piece_id in range(n_pieces):\n",
    "                if piece_id in placed:\n",
    "                    continue\n",
    "                \n",
    "                total_score = 0\n",
    "                for neighbor_id, neighbor_edge in neighbors:\n",
    "                    my_edge = get_complementary_edge(neighbor_edge)\n",
    "                    my_edge_idx = edge_names.index(my_edge)\n",
    "                    neighbor_edge_idx = edge_names.index(neighbor_edge)\n",
    "                    score = compatibility_matrix[piece_id, my_edge_idx, neighbor_id, neighbor_edge_idx]\n",
    "                    total_score += score\n",
    "                \n",
    "                avg_score = total_score / len(neighbors)\n",
    "                piece_scores.append((piece_id, avg_score))\n",
    "            \n",
    "            piece_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "            \n",
    "            for piece_id, score in piece_scores[:beam_width]:\n",
    "                new_arrangement = arrangement.copy()\n",
    "                new_arrangement[row, col] = piece_id\n",
    "                new_placed = placed.copy()\n",
    "                new_placed.add(piece_id)\n",
    "                new_score = cumulative_score + score\n",
    "                new_candidates.append((new_arrangement, new_placed, new_score))\n",
    "        \n",
    "        new_candidates.sort(key=lambda x: x[2], reverse=True)\n",
    "        beam = new_candidates[:beam_width]\n",
    "    \n",
    "    return beam[0][0] if beam else np.full((grid_size, grid_size), -1, dtype=int)\n",
    "\n",
    "print(\"âœ… Beam search helper defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46129bba",
   "metadata": {},
   "source": [
    "# Overlap-Based Solver Testing\n",
    "\n",
    "Testing the new overlap-based hierarchical approach that addresses the main limitation of fixed quadrant boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6658aac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Overlap solver test function defined\n"
     ]
    }
   ],
   "source": [
    "# Test Overlap Solver on Sample Puzzles\n",
    "import overlap_solver\n",
    "importlib.reload(overlap_solver)\n",
    "from overlap_solver import solve_8x8_with_overlap\n",
    "\n",
    "def test_overlap_solver(puzzle_id: int, overlap: int = 1, verbose: bool = True) -> Dict:\n",
    "    \"\"\"\n",
    "    Test overlap solver on a single puzzle.\n",
    "    \n",
    "    Args:\n",
    "        puzzle_id: ID of the puzzle\n",
    "        overlap: Number of pieces to overlap (1 or 2)\n",
    "        verbose: Print detailed progress\n",
    "    \"\"\"\n",
    "    puzzle_folder = 'puzzle_8x8'\n",
    "    grid_size = 8\n",
    "    \n",
    "    # Build paths\n",
    "    original_path = DATASET_ROOT / puzzle_folder / f\"{puzzle_id}.jpg\"\n",
    "    enhanced_path = ENHANCED_DIR / f\"{puzzle_folder}_{puzzle_id}.jpg\"\n",
    "    mask_path = MASK_DIR / f\"{puzzle_folder}_{puzzle_id}.jpg\"\n",
    "    ground_truth_path = CORRECT_DIR / f\"{puzzle_id}.png\"\n",
    "    \n",
    "    if not all([p.exists() for p in [original_path, enhanced_path, mask_path, ground_truth_path]]):\n",
    "        return {'error': 'Missing files'}\n",
    "    \n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Load images\n",
    "        ground_truth = cv2.imread(str(ground_truth_path))\n",
    "        \n",
    "        # Create pieces\n",
    "        pieces = create_puzzle_pieces(\n",
    "            str(original_path), str(enhanced_path), str(mask_path), grid_size\n",
    "        )\n",
    "        \n",
    "        # Build compatibility matrix\n",
    "        compatibility_matrix = build_compatibility_matrix(pieces, strip_width=3, grid_size=grid_size)\n",
    "        \n",
    "        # Solve using overlap approach\n",
    "        arrangement, ssim_score = solve_8x8_with_overlap(\n",
    "            pieces, compatibility_matrix, ground_truth,\n",
    "            overlap=overlap, beam_width=7, verbose=verbose\n",
    "        )\n",
    "        \n",
    "        # Assemble\n",
    "        assembled = assemble_puzzle(pieces, arrangement, grid_size)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        \n",
    "        # Compute additional metrics\n",
    "        image_metrics = compute_accuracy_metrics(assembled, ground_truth)\n",
    "        piece_accuracy = compute_piece_placement_accuracy(arrangement, pieces)\n",
    "        \n",
    "        # Save\n",
    "        output_path = ASSEMBLED_DIR / f\"{puzzle_id}_overlap_{overlap}.jpg\"\n",
    "        cv2.imwrite(str(output_path), assembled)\n",
    "        \n",
    "        return {\n",
    "            'puzzle_id': puzzle_id,\n",
    "            'overlap': overlap,\n",
    "            'ssim': ssim_score,\n",
    "            'mse': image_metrics['mse'],\n",
    "            'psnr': image_metrics['psnr'],\n",
    "            'piece_accuracy': piece_accuracy,\n",
    "            'elapsed_time': elapsed_time,\n",
    "            'assembled_path': str(output_path)\n",
    "        }\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        return {'error': str(e), 'puzzle_id': puzzle_id, 'traceback': traceback.format_exc()}\n",
    "\n",
    "print(\"âœ… Overlap solver test function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46321e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing Overlap Solver on 10 Sample Puzzles ===\n",
      "\n",
      "Testing puzzle 0... âœ… SSIM: 0.1409 | Time: 19.0s\n",
      "Testing puzzle 1... âœ… SSIM: 0.1409 | Time: 19.0s\n",
      "Testing puzzle 1... âœ… SSIM: 0.2061 | Time: 18.5s\n",
      "Testing puzzle 2... âœ… SSIM: 0.2061 | Time: 18.5s\n",
      "Testing puzzle 2... âœ… SSIM: 0.1878 | Time: 17.7s\n",
      "Testing puzzle 3... âœ… SSIM: 0.1878 | Time: 17.7s\n",
      "Testing puzzle 3... âœ… SSIM: 0.0979 | Time: 19.1s\n",
      "Testing puzzle 4... âœ… SSIM: 0.0979 | Time: 19.1s\n",
      "Testing puzzle 4... âœ… SSIM: 0.0798 | Time: 18.4s\n",
      "Testing puzzle 5... âœ… SSIM: 0.0798 | Time: 18.4s\n",
      "Testing puzzle 5... âœ… SSIM: 0.0560 | Time: 18.7s\n",
      "Testing puzzle 6... âœ… SSIM: 0.0560 | Time: 18.7s\n",
      "Testing puzzle 6... âœ… SSIM: 0.0524 | Time: 17.5s\n",
      "Testing puzzle 7... âœ… SSIM: 0.0524 | Time: 17.5s\n",
      "Testing puzzle 7... âœ… SSIM: 0.1915 | Time: 17.0s\n",
      "Testing puzzle 8... âœ… SSIM: 0.1915 | Time: 17.0s\n",
      "Testing puzzle 8... âœ… SSIM: 0.1873 | Time: 17.4s\n",
      "Testing puzzle 9... âœ… SSIM: 0.1873 | Time: 17.4s\n",
      "Testing puzzle 9... âœ… SSIM: 0.2002 | Time: 17.2s\n",
      "\n",
      "============================================================\n",
      "OVERLAP SOLVER - SAMPLE RESULTS (10 puzzles)\n",
      "============================================================\n",
      "Successful: 10/10\n",
      "\n",
      "SSIM Scores:\n",
      "  Mean:   0.1400\n",
      "  Median: 0.1641\n",
      "  Min:    0.0524\n",
      "  Max:    0.2061\n",
      "\n",
      "Processing Time:\n",
      "  Mean:   18.1s\n",
      "  Total:  3.0 min\n",
      "\n",
      "Baseline Comparison:\n",
      "  Hierarchical (no overlap): 0.218\n",
      "  Overlap solver:            0.140\n",
      "  Improvement:               -35.8%\n",
      "âœ… SSIM: 0.2002 | Time: 17.2s\n",
      "\n",
      "============================================================\n",
      "OVERLAP SOLVER - SAMPLE RESULTS (10 puzzles)\n",
      "============================================================\n",
      "Successful: 10/10\n",
      "\n",
      "SSIM Scores:\n",
      "  Mean:   0.1400\n",
      "  Median: 0.1641\n",
      "  Min:    0.0524\n",
      "  Max:    0.2061\n",
      "\n",
      "Processing Time:\n",
      "  Mean:   18.1s\n",
      "  Total:  3.0 min\n",
      "\n",
      "Baseline Comparison:\n",
      "  Hierarchical (no overlap): 0.218\n",
      "  Overlap solver:            0.140\n",
      "  Improvement:               -35.8%\n"
     ]
    }
   ],
   "source": [
    "# Test on 10 Sample Puzzles\n",
    "print(\"\\n=== Testing Overlap Solver on 10 Sample Puzzles ===\\n\")\n",
    "\n",
    "sample_ids = list(range(10))  # Puzzles 0-9\n",
    "overlap_results = []\n",
    "\n",
    "for puzzle_id in sample_ids:\n",
    "    print(f\"Testing puzzle {puzzle_id}...\", end=\" \")\n",
    "    result = test_overlap_solver(puzzle_id, overlap=1, verbose=False)\n",
    "    \n",
    "    if 'error' not in result:\n",
    "        print(f\"âœ… SSIM: {result['ssim']:.4f} | Time: {result['elapsed_time']:.1f}s\")\n",
    "        overlap_results.append(result)\n",
    "    else:\n",
    "        print(f\"âŒ Error: {result['error'][:50]}\")\n",
    "        overlap_results.append(result)\n",
    "\n",
    "# Summary\n",
    "successful = [r for r in overlap_results if 'error' not in r]\n",
    "if successful:\n",
    "    ssim_scores = [r['ssim'] for r in successful]\n",
    "    times = [r['elapsed_time'] for r in successful]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"OVERLAP SOLVER - SAMPLE RESULTS (10 puzzles)\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Successful: {len(successful)}/10\")\n",
    "    print(f\"\\nSSIM Scores:\")\n",
    "    print(f\"  Mean:   {np.mean(ssim_scores):.4f}\")\n",
    "    print(f\"  Median: {np.median(ssim_scores):.4f}\")\n",
    "    print(f\"  Min:    {np.min(ssim_scores):.4f}\")\n",
    "    print(f\"  Max:    {np.max(ssim_scores):.4f}\")\n",
    "    print(f\"\\nProcessing Time:\")\n",
    "    print(f\"  Mean:   {np.mean(times):.1f}s\")\n",
    "    print(f\"  Total:  {np.sum(times)/60:.1f} min\")\n",
    "    \n",
    "    # Compare to baseline (hierarchical without overlap)\n",
    "    baseline_ssim = 0.218  # From previous results\n",
    "    improvement = (np.mean(ssim_scores) - baseline_ssim) / baseline_ssim * 100\n",
    "    print(f\"\\nBaseline Comparison:\")\n",
    "    print(f\"  Hierarchical (no overlap): {baseline_ssim:.3f}\")\n",
    "    print(f\"  Overlap solver:            {np.mean(ssim_scores):.3f}\")\n",
    "    print(f\"  Improvement:               {improvement:+.1f}%\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ No successful puzzles to analyze\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a33a75c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Debugging Overlap Solver vs Hierarchical ===\n",
      "\n",
      "Testing hierarchical solver...\n",
      "Hierarchical SSIM: 0.1797\n",
      "\n",
      "=== Solving 8Ã—8 with 1-piece overlap ===\n",
      "Created 4 overlapping 4Ã—4 regions\n",
      "  Solving region 1/4 at offset (0, 0)\n",
      "Hierarchical SSIM: 0.1797\n",
      "\n",
      "=== Solving 8Ã—8 with 1-piece overlap ===\n",
      "Created 4 overlapping 4Ã—4 regions\n",
      "  Solving region 1/4 at offset (0, 0)\n",
      "    Region SSIM: 0.1440\n",
      "  Solving region 2/4 at offset (0, 3)\n",
      "    Region SSIM: 0.1440\n",
      "  Solving region 2/4 at offset (0, 3)\n",
      "    Region SSIM: 0.3446\n",
      "  Solving region 3/4 at offset (3, 0)\n",
      "    Region SSIM: 0.3446\n",
      "  Solving region 3/4 at offset (3, 0)\n",
      "    Region SSIM: 0.1977\n",
      "  Solving region 4/4 at offset (3, 3)\n",
      "    Region SSIM: 0.1977\n",
      "  Solving region 4/4 at offset (3, 3)\n",
      "    Region SSIM: 0.1851\n",
      "\n",
      "Merging overlapping regions...\n",
      "  Merged regions: 49/64 positions filled\n",
      "\n",
      "Resolving conflicts...\n",
      "  Found 7 duplicate pieces\n",
      "  Filling 21 empty positions with 22 unused pieces\n",
      "\n",
      "âœ… Final SSIM: 0.2062\n",
      "\n",
      "Overlap SSIM: 0.2062\n",
      "Difference: 0.0264\n",
      "    Region SSIM: 0.1851\n",
      "\n",
      "Merging overlapping regions...\n",
      "  Merged regions: 49/64 positions filled\n",
      "\n",
      "Resolving conflicts...\n",
      "  Found 7 duplicate pieces\n",
      "  Filling 21 empty positions with 22 unused pieces\n",
      "\n",
      "âœ… Final SSIM: 0.2062\n",
      "\n",
      "Overlap SSIM: 0.2062\n",
      "Difference: 0.0264\n"
     ]
    }
   ],
   "source": [
    "# Debug: Compare overlap solver with hierarchical solver on single puzzle\n",
    "print(\"\\n=== Debugging Overlap Solver vs Hierarchical ===\\n\")\n",
    "\n",
    "test_id = 2  # Use puzzle 2 which had decent SSIM\n",
    "\n",
    "# Test hierarchical solver\n",
    "print(\"Testing hierarchical solver...\")\n",
    "puzzle_folder = 'puzzle_8x8'\n",
    "grid_size = 8\n",
    "original_path = DATASET_ROOT / puzzle_folder / f\"{test_id}.jpg\"\n",
    "enhanced_path = ENHANCED_DIR / f\"{puzzle_folder}_{test_id}.jpg\"\n",
    "mask_path = MASK_DIR / f\"{puzzle_folder}_{test_id}.jpg\"\n",
    "ground_truth_path = CORRECT_DIR / f\"{test_id}.png\"\n",
    "\n",
    "ground_truth = cv2.imread(str(ground_truth_path))\n",
    "pieces = create_puzzle_pieces(str(original_path), str(enhanced_path), str(mask_path), grid_size)\n",
    "compatibility_matrix = build_compatibility_matrix(pieces, strip_width=3, grid_size=grid_size)\n",
    "\n",
    "# Hierarchical (baseline) - correct parameter order\n",
    "hierarchical_result, hier_ssim = hierarchical_solve(\n",
    "    pieces, compatibility_matrix, grid_size, \n",
    "    greedy_assemble_with_beam, ground_truth, verbose=False\n",
    ")\n",
    "hier_assembled = assemble_puzzle(pieces, hierarchical_result, grid_size)\n",
    "hier_metrics = compute_accuracy_metrics(hier_assembled, ground_truth)\n",
    "\n",
    "print(f\"Hierarchical SSIM: {hier_metrics['ssim']:.4f}\")\n",
    "\n",
    "# Overlap\n",
    "overlap_result, overlap_ssim = solve_8x8_with_overlap(\n",
    "    pieces, compatibility_matrix, ground_truth, \n",
    "    overlap=1, verbose=True\n",
    ")\n",
    "overlap_assembled = assemble_puzzle(pieces, overlap_result, grid_size)\n",
    "overlap_metrics = compute_accuracy_metrics(overlap_assembled, ground_truth)\n",
    "\n",
    "print(f\"\\nOverlap SSIM: {overlap_metrics['ssim']:.4f}\")\n",
    "print(f\"Difference: {(overlap_metrics['ssim'] - hier_metrics['ssim']):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247fcc89",
   "metadata": {},
   "source": [
    "# Multi-Level Hierarchy Testing (8â†’4â†’2)\n",
    "\n",
    "Leveraging the excellent 2Ã—2 solver (75.3% SSIM) to build up to 8Ã—8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "048962b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Multi-level solver test function defined\n"
     ]
    }
   ],
   "source": [
    "# Test Multi-Level Solver\n",
    "import multilevel_solver\n",
    "importlib.reload(multilevel_solver)\n",
    "from multilevel_solver import solve_8x8_multilevel\n",
    "\n",
    "def test_multilevel_solver(puzzle_id: int, verbose: bool = True) -> Dict:\n",
    "    \"\"\"\n",
    "    Test multi-level hierarchical solver on a single puzzle.\n",
    "    \"\"\"\n",
    "    puzzle_folder = 'puzzle_8x8'\n",
    "    grid_size = 8\n",
    "    \n",
    "    # Build paths\n",
    "    original_path = DATASET_ROOT / puzzle_folder / f\"{puzzle_id}.jpg\"\n",
    "    enhanced_path = ENHANCED_DIR / f\"{puzzle_folder}_{puzzle_id}.jpg\"\n",
    "    mask_path = MASK_DIR / f\"{puzzle_folder}_{puzzle_id}.jpg\"\n",
    "    ground_truth_path = CORRECT_DIR / f\"{puzzle_id}.png\"\n",
    "    \n",
    "    if not all([p.exists() for p in [original_path, enhanced_path, mask_path, ground_truth_path]]):\n",
    "        return {'error': 'Missing files'}\n",
    "    \n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Load images\n",
    "        ground_truth = cv2.imread(str(ground_truth_path))\n",
    "        \n",
    "        # Create pieces\n",
    "        pieces = create_puzzle_pieces(\n",
    "            str(original_path), str(enhanced_path), str(mask_path), grid_size\n",
    "        )\n",
    "        \n",
    "        # Build compatibility matrix\n",
    "        compatibility_matrix = build_compatibility_matrix(pieces, strip_width=3, grid_size=grid_size)\n",
    "        \n",
    "        # Solve using multi-level approach\n",
    "        arrangement, ssim_score = solve_8x8_multilevel(\n",
    "            pieces, compatibility_matrix, ground_truth, verbose=verbose\n",
    "        )\n",
    "        \n",
    "        # Assemble\n",
    "        assembled = assemble_puzzle(pieces, arrangement, grid_size)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        \n",
    "        # Compute additional metrics\n",
    "        image_metrics = compute_accuracy_metrics(assembled, ground_truth)\n",
    "        piece_accuracy = compute_piece_placement_accuracy(arrangement, pieces)\n",
    "        \n",
    "        # Save\n",
    "        output_path = ASSEMBLED_DIR / f\"{puzzle_id}_multilevel.jpg\"\n",
    "        cv2.imwrite(str(output_path), assembled)\n",
    "        \n",
    "        return {\n",
    "            'puzzle_id': puzzle_id,\n",
    "            'ssim': ssim_score,\n",
    "            'mse': image_metrics['mse'],\n",
    "            'psnr': image_metrics['psnr'],\n",
    "            'piece_accuracy': piece_accuracy,\n",
    "            'elapsed_time': elapsed_time,\n",
    "            'assembled_path': str(output_path)\n",
    "        }\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        return {'error': str(e), 'puzzle_id': puzzle_id, 'traceback': traceback.format_exc()}\n",
    "\n",
    "print(\"âœ… Multi-level solver test function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8edceff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing Multi-Level Solver on 10 Sample Puzzles ===\n",
      "\n",
      "Testing puzzle 0... âœ… SSIM: 0.0963 | Time: 16.5s\n",
      "Testing puzzle 1... âœ… SSIM: 0.1573 | Time: 16.5s\n",
      "Testing puzzle 2... âœ… SSIM: 0.1794 | Time: 16.0s\n",
      "Testing puzzle 3... âœ… SSIM: 0.0997 | Time: 16.3s\n",
      "Testing puzzle 4... âœ… SSIM: 0.0978 | Time: 15.4s\n",
      "Testing puzzle 5... âœ… SSIM: 0.0615 | Time: 17.1s\n",
      "Testing puzzle 6... âœ… SSIM: 0.0683 | Time: 17.7s\n",
      "Testing puzzle 7... âœ… SSIM: 0.1591 | Time: 15.2s\n",
      "Testing puzzle 8... âœ… SSIM: 0.2066 | Time: 15.2s\n",
      "Testing puzzle 9... âœ… SSIM: 0.1795 | Time: 14.7s\n",
      "\n",
      "============================================================\n",
      "MULTI-LEVEL SOLVER - SAMPLE RESULTS (10 puzzles)\n",
      "============================================================\n",
      "Successful: 10/10\n",
      "\n",
      "SSIM Scores:\n",
      "  Mean:   0.1305\n",
      "  Median: 0.1285\n",
      "  Min:    0.0615\n",
      "  Max:    0.2066\n",
      "\n",
      "Processing Time:\n",
      "  Mean:   16.1s\n",
      "  Total:  2.7 min\n",
      "\n",
      "Baseline Comparisons:\n",
      "  Hierarchical (baseline):   0.218\n",
      "  Overlap solver:            0.140\n",
      "  Multi-level (8â†’4â†’2):       0.131\n",
      "  vs Hierarchical:           -40.1%\n",
      "  vs Overlap:                -6.8%\n"
     ]
    }
   ],
   "source": [
    "# Test Multi-Level on 10 Sample Puzzles\n",
    "print(\"\\n=== Testing Multi-Level Solver on 10 Sample Puzzles ===\\n\")\n",
    "\n",
    "sample_ids = list(range(10))  # Puzzles 0-9\n",
    "multilevel_results = []\n",
    "\n",
    "for puzzle_id in sample_ids:\n",
    "    print(f\"Testing puzzle {puzzle_id}...\", end=\" \")\n",
    "    result = test_multilevel_solver(puzzle_id, verbose=False)\n",
    "    \n",
    "    if 'error' not in result:\n",
    "        print(f\"âœ… SSIM: {result['ssim']:.4f} | Time: {result['elapsed_time']:.1f}s\")\n",
    "        multilevel_results.append(result)\n",
    "    else:\n",
    "        print(f\"âŒ Error: {result['error'][:80]}\")\n",
    "        if 'traceback' in result:\n",
    "            print(f\"   {result['traceback'][:200]}\")\n",
    "        multilevel_results.append(result)\n",
    "\n",
    "# Summary\n",
    "successful = [r for r in multilevel_results if 'error' not in r]\n",
    "if successful:\n",
    "    ssim_scores = [r['ssim'] for r in successful]\n",
    "    times = [r['elapsed_time'] for r in successful]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"MULTI-LEVEL SOLVER - SAMPLE RESULTS (10 puzzles)\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Successful: {len(successful)}/10\")\n",
    "    print(f\"\\nSSIM Scores:\")\n",
    "    print(f\"  Mean:   {np.mean(ssim_scores):.4f}\")\n",
    "    print(f\"  Median: {np.median(ssim_scores):.4f}\")\n",
    "    print(f\"  Min:    {np.min(ssim_scores):.4f}\")\n",
    "    print(f\"  Max:    {np.max(ssim_scores):.4f}\")\n",
    "    print(f\"\\nProcessing Time:\")\n",
    "    print(f\"  Mean:   {np.mean(times):.1f}s\")\n",
    "    print(f\"  Total:  {np.sum(times)/60:.1f} min\")\n",
    "    \n",
    "    # Compare to baselines\n",
    "    hier_baseline = 0.218  # Hierarchical without overlap\n",
    "    overlap_baseline = 0.140  # Overlap solver\n",
    "    improvement_vs_hier = (np.mean(ssim_scores) - hier_baseline) / hier_baseline * 100\n",
    "    improvement_vs_overlap = (np.mean(ssim_scores) - overlap_baseline) / overlap_baseline * 100\n",
    "    \n",
    "    print(f\"\\nBaseline Comparisons:\")\n",
    "    print(f\"  Hierarchical (baseline):   {hier_baseline:.3f}\")\n",
    "    print(f\"  Overlap solver:            {overlap_baseline:.3f}\")\n",
    "    print(f\"  Multi-level (8â†’4â†’2):       {np.mean(ssim_scores):.3f}\")\n",
    "    print(f\"  vs Hierarchical:           {improvement_vs_hier:+.1f}%\")\n",
    "    print(f\"  vs Overlap:                {improvement_vs_overlap:+.1f}%\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ No successful puzzles to analyze\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6427d8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Debugging Multi-Level Components ===\n",
      "\n",
      "1. Hierarchical (baseline):\n",
      "   SSIM: 0.1797\n",
      "\n",
      "2. Multi-level (8â†’4â†’2):\n",
      "\n",
      "=== Multi-Level Hierarchical Solve (8Ã—8 â†’ 4Ã—4 â†’ 2Ã—2) ===\n",
      "\n",
      "Solving 4Ã—4 quadrant 1/4 using 2Ã—2 blocks...\n",
      "  Solving 2Ã—2 block 1/4...\n",
      "  Solving 2Ã—2 block 2/4...\n",
      "  Solving 2Ã—2 block 3/4...\n",
      "  Solving 2Ã—2 block 4/4...\n",
      "  4Ã—4 from 2Ã—2 blocks SSIM: 0.1684\n",
      "  Quadrant 1 SSIM: 0.1684\n",
      "\n",
      "Solving 4Ã—4 quadrant 2/4 using 2Ã—2 blocks...\n",
      "  Solving 2Ã—2 block 1/4...\n",
      "  Solving 2Ã—2 block 2/4...\n",
      "  Solving 2Ã—2 block 3/4...\n",
      "  Solving 2Ã—2 block 4/4...\n",
      "  4Ã—4 from 2Ã—2 blocks SSIM: 0.1079\n",
      "  Quadrant 2 SSIM: 0.1079\n",
      "\n",
      "Solving 4Ã—4 quadrant 3/4 using 2Ã—2 blocks...\n",
      "  Solving 2Ã—2 block 1/4...\n",
      "  Solving 2Ã—2 block 2/4...\n",
      "  Solving 2Ã—2 block 3/4...\n",
      "  Solving 2Ã—2 block 4/4...\n",
      "  4Ã—4 from 2Ã—2 blocks SSIM: 0.2124\n",
      "  Quadrant 3 SSIM: 0.2124\n",
      "\n",
      "Solving 4Ã—4 quadrant 4/4 using 2Ã—2 blocks...\n",
      "  Solving 2Ã—2 block 1/4...\n",
      "  Solving 2Ã—2 block 2/4...\n",
      "  Solving 2Ã—2 block 3/4...\n",
      "  Solving 2Ã—2 block 4/4...\n",
      "  4Ã—4 from 2Ã—2 blocks SSIM: 0.2186\n",
      "  Quadrant 4 SSIM: 0.2186\n",
      "\n",
      "Refining seams between quadrants...\n",
      "  Initial SSIM: 0.1728\n",
      "    Iteration 1: Swap (0,3)-(0,4) â†’ SSIM 0.1745\n",
      "    Iteration 2: Swap (3,4)-(4,4) â†’ SSIM 0.1757\n",
      "    Iteration 3: Swap (3,2)-(4,2) â†’ SSIM 0.1776\n",
      "    Iteration 4: Swap (3,5)-(3,6) â†’ SSIM 0.1794\n",
      "  Seam refinement: 5 iterations, final SSIM 0.1794\n",
      "\n",
      "âœ… Final 8Ã—8 SSIM: 0.1794\n",
      "   Final SSIM: 0.1794\n",
      "\n",
      "Comparison: Multi-level is -0.2% vs Hierarchical\n"
     ]
    }
   ],
   "source": [
    "# Debug Multi-Level - Compare Individual Components\n",
    "print(\"\\n=== Debugging Multi-Level Components ===\\n\")\n",
    "\n",
    "test_id = 2\n",
    "puzzle_folder = 'puzzle_8x8'\n",
    "grid_size = 8\n",
    "\n",
    "# Load puzzle\n",
    "original_path = DATASET_ROOT / puzzle_folder / f\"{test_id}.jpg\"\n",
    "enhanced_path = ENHANCED_DIR / f\"{puzzle_folder}_{test_id}.jpg\"\n",
    "mask_path = MASK_DIR / f\"{puzzle_folder}_{test_id}.jpg\"\n",
    "ground_truth_path = CORRECT_DIR / f\"{test_id}.png\"\n",
    "\n",
    "ground_truth = cv2.imread(str(ground_truth_path))\n",
    "pieces = create_puzzle_pieces(str(original_path), str(enhanced_path), str(mask_path), grid_size)\n",
    "compatibility_matrix = build_compatibility_matrix(pieces, strip_width=3, grid_size=grid_size)\n",
    "\n",
    "# Test hierarchical (baseline)\n",
    "print(\"1. Hierarchical (baseline):\")\n",
    "hier_arr, hier_score = hierarchical_solve(pieces, compatibility_matrix, grid_size, \n",
    "                                         greedy_assemble_with_beam, ground_truth, verbose=False)\n",
    "print(f\"   SSIM: {hier_score:.4f}\")\n",
    "\n",
    "# Test multi-level\n",
    "print(\"\\n2. Multi-level (8â†’4â†’2):\")\n",
    "ml_result = test_multilevel_solver(test_id, verbose=True)\n",
    "if 'error' not in ml_result:\n",
    "    print(f\"   Final SSIM: {ml_result['ssim']:.4f}\")\n",
    "else:\n",
    "    print(f\"   Error: {ml_result['error']}\")\n",
    "\n",
    "print(f\"\\nComparison: Multi-level is {(ml_result['ssim']/hier_score - 1)*100:.1f}% vs Hierarchical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88636244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Single 8Ã—8 Puzzle\n",
    "def process_8x8_puzzle(puzzle_id: int, verbose: bool = False) -> Dict:\n",
    "    \"\"\"\n",
    "    Process a single 8Ã—8 puzzle using hierarchical SSIM-validated approach.\n",
    "    \"\"\"\n",
    "    puzzle_folder = 'puzzle_8x8'\n",
    "    grid_size = 8\n",
    "    \n",
    "    # Build paths\n",
    "    original_path = DATASET_ROOT / puzzle_folder / f\"{puzzle_id}.jpg\"\n",
    "    enhanced_path = ENHANCED_DIR / f\"{puzzle_folder}_{puzzle_id}.jpg\"\n",
    "    mask_path = MASK_DIR / f\"{puzzle_folder}_{puzzle_id}.jpg\"\n",
    "    ground_truth_path = CORRECT_DIR / f\"{puzzle_id}.png\"\n",
    "    \n",
    "    if not all([p.exists() for p in [original_path, enhanced_path, mask_path, ground_truth_path]]):\n",
    "        return {'error': 'Missing files'}\n",
    "    \n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Load images\n",
    "        ground_truth = cv2.imread(str(ground_truth_path))\n",
    "        \n",
    "        # Create pieces\n",
    "        pieces = create_puzzle_pieces(\n",
    "            str(original_path), str(enhanced_path), str(mask_path), grid_size\n",
    "        )\n",
    "        \n",
    "        # Build compatibility matrix\n",
    "        compatibility_matrix = build_compatibility_matrix(pieces, strip_width=3, grid_size=grid_size)\n",
    "        \n",
    "        # Solve using hierarchical approach\n",
    "        arrangement, best_score = hierarchical_solve(\n",
    "            pieces, compatibility_matrix, grid_size,\n",
    "            greedy_assemble_with_beam, ground_truth=ground_truth, verbose=verbose\n",
    "        )\n",
    "        \n",
    "        # Assemble\n",
    "        assembled = assemble_puzzle(pieces, arrangement, grid_size)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        \n",
    "        # Compute metrics\n",
    "        image_metrics = compute_accuracy_metrics(assembled, ground_truth)\n",
    "        piece_accuracy = compute_piece_placement_accuracy(arrangement, pieces)\n",
    "        \n",
    "        # Save\n",
    "        output_path = ASSEMBLED_DIR / f\"{puzzle_id}_assembled.jpg\"\n",
    "        cv2.imwrite(str(output_path), assembled)\n",
    "        \n",
    "        return {\n",
    "            'puzzle_id': puzzle_id,\n",
    "            'ssim': image_metrics['ssim'],\n",
    "            'mse': image_metrics['mse'],\n",
    "            'psnr': image_metrics['psnr'],\n",
    "            'piece_accuracy': piece_accuracy,\n",
    "            'elapsed_time': elapsed_time,\n",
    "            'best_score': float(best_score),\n",
    "            'assembled_path': str(output_path)\n",
    "        }\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        return {'error': str(e), 'puzzle_id': puzzle_id, 'traceback': traceback.format_exc()}\n",
    "\n",
    "print(\"âœ… 8Ã—8 processing function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dcada6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Single Puzzle with Verbose Output\n",
    "print(\"\\n=== Testing 8Ã—8 Solver (Verbose) ===\")\n",
    "test_result = process_8x8_puzzle(0, verbose=True)\n",
    "\n",
    "if 'error' not in test_result:\n",
    "    print(f\"\\nâœ… Test successful:\")\n",
    "    print(f\"  SSIM: {test_result['ssim']:.4f}\")\n",
    "    print(f\"  Time: {test_result['elapsed_time']:.2f}s\")\n",
    "    print(f\"  Internal Score: {test_result['best_score']:.4f}\")\n",
    "else:\n",
    "    print(f\"\\nâŒ Error: {test_result['error']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b17569d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process All 8Ã—8 Puzzles\n",
    "results_8x8 = []\n",
    "TOTAL_PUZZLES = 110\n",
    "\n",
    "print(\"\\n=== Processing 8Ã—8 Puzzles ===\")\n",
    "start_time = time.time()\n",
    "\n",
    "for puzzle_id in tqdm(range(TOTAL_PUZZLES), desc=\"8Ã—8 Puzzles\"):\n",
    "    result = process_8x8_puzzle(puzzle_id, verbose=False)\n",
    "    results_8x8.append(result)\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "# Filter successful results\n",
    "successful = [r for r in results_8x8 if 'error' not in r]\n",
    "failed = [r for r in results_8x8 if 'error' in r]\n",
    "\n",
    "print(f\"\\nâœ… Complete: {len(successful)}/{TOTAL_PUZZLES} successful\")\n",
    "print(f\"â±ï¸ Total time: {elapsed/60:.1f} min ({elapsed/TOTAL_PUZZLES:.2f}s per puzzle)\")\n",
    "\n",
    "if failed:\n",
    "    print(f\"\\nâš ï¸ {len(failed)} puzzles failed:\")\n",
    "    for r in failed[:3]:\n",
    "        print(f\"  - Puzzle {r['puzzle_id']}: {r['error']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288fbdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze Results\n",
    "if successful:\n",
    "    ssim_scores = [r['ssim'] for r in successful]\n",
    "    piece_accuracies = [r['piece_accuracy'] for r in successful]\n",
    "    times = [r['elapsed_time'] for r in successful]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"8Ã—8 PUZZLE RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nSSIM Scores:\")\n",
    "    print(f\"  Mean:   {np.mean(ssim_scores):.4f}\")\n",
    "    print(f\"  Median: {np.median(ssim_scores):.4f}\")\n",
    "    print(f\"  Std:    {np.std(ssim_scores):.4f}\")\n",
    "    print(f\"  Min:    {np.min(ssim_scores):.4f}\")\n",
    "    print(f\"  Max:    {np.max(ssim_scores):.4f}\")\n",
    "    \n",
    "    print(f\"\\nProcessing Time:\")\n",
    "    print(f\"  Mean: {np.mean(times):.2f}s\")\n",
    "    print(f\"  Total: {np.sum(times)/60:.1f} min\")\n",
    "    \n",
    "    print(f\"\\nBaseline Comparison:\")\n",
    "    baseline = 0.107\n",
    "    improvement = (np.mean(ssim_scores) - baseline) / baseline * 100\n",
    "    print(f\"  Baseline: {baseline:.3f}\")\n",
    "    print(f\"  Current:  {np.mean(ssim_scores):.3f}\")\n",
    "    print(f\"  Improvement: +{improvement:.1f}% ({np.mean(ssim_scores)/baseline:.2f}Ã—)\")\n",
    "    \n",
    "    # Save results\n",
    "    results_file = RESULTS_DIR / \"results_8x8.json\"\n",
    "    with open(results_file, 'w') as f:\n",
    "        json.dump(results_8x8, f, indent=2)\n",
    "    print(f\"\\nðŸ’¾ Results saved to: {results_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c09a78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Results\n",
    "if successful:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    fig.suptitle('8Ã—8 Puzzle Results - SSIM-Validated Hierarchical', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # SSIM distribution\n",
    "    axes[0, 0].hist(ssim_scores, bins=30, alpha=0.7, edgecolor='black', color='steelblue')\n",
    "    axes[0, 0].axvline(np.mean(ssim_scores), color='red', linestyle='--', linewidth=2, label=f'Mean: {np.mean(ssim_scores):.3f}')\n",
    "    axes[0, 0].axvline(0.107, color='orange', linestyle='--', linewidth=2, label='Baseline: 0.107')\n",
    "    axes[0, 0].set_xlabel('SSIM Score')\n",
    "    axes[0, 0].set_ylabel('Frequency')\n",
    "    axes[0, 0].set_title('SSIM Distribution')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(alpha=0.3)\n",
    "    \n",
    "    # Processing time\n",
    "    axes[0, 1].hist(times, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axes[0, 1].axvline(np.mean(times), color='red', linestyle='--', linewidth=2, label=f'Mean: {np.mean(times):.2f}s')\n",
    "    axes[0, 1].set_xlabel('Processing Time (s)')\n",
    "    axes[0, 1].set_ylabel('Frequency')\n",
    "    axes[0, 1].set_title('Processing Time Distribution')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(alpha=0.3)\n",
    "    \n",
    "    # SSIM box plot\n",
    "    axes[1, 0].boxplot(ssim_scores)\n",
    "    axes[1, 0].axhline(0.107, color='orange', linestyle='--', linewidth=2, label='Baseline')\n",
    "    axes[1, 0].set_ylabel('SSIM Score')\n",
    "    axes[1, 0].set_title('SSIM Box Plot')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(alpha=0.3)\n",
    "    \n",
    "    # Best vs Worst\n",
    "    sorted_results = sorted(successful, key=lambda x: x['ssim'])\n",
    "    best_5 = [r['ssim'] for r in sorted_results[-5:]]\n",
    "    worst_5 = [r['ssim'] for r in sorted_results[:5]]\n",
    "    \n",
    "    x = np.arange(5)\n",
    "    width = 0.35\n",
    "    axes[1, 1].bar(x - width/2, worst_5, width, label='Worst 5', color='crimson', alpha=0.7)\n",
    "    axes[1, 1].bar(x + width/2, best_5, width, label='Best 5', color='green', alpha=0.7)\n",
    "    axes[1, 1].set_ylabel('SSIM Score')\n",
    "    axes[1, 1].set_title('Best vs Worst Puzzles')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(RESULTS_DIR / 'results_8x8_analysis.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"âœ… Visualization saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47a5f1f",
   "metadata": {},
   "source": [
    "## Future Improvements\n",
    "\n",
    "### 1. Adaptive Quadrant Boundaries\n",
    "- Analyze image content (edges, regions)\n",
    "- Split along natural boundaries\n",
    "- Avoid cutting through important features\n",
    "\n",
    "### 2. Overlap Regions\n",
    "- Solve quadrants with 1-2 piece overlap\n",
    "- Use overlap to validate and refine seams\n",
    "- Weighted averaging in overlap zones\n",
    "\n",
    "### 3. Multi-Level Hierarchy\n",
    "- 8Ã—8 â†’ four 4Ã—4 â†’ sixteen 2Ã—2\n",
    "- Bottom-up assembly from 2Ã—2 blocks\n",
    "- Better error containment at each level\n",
    "\n",
    "### 4. Graph-Based Optimization\n",
    "- Model as minimum cost perfect matching problem\n",
    "- Use Hungarian algorithm or network flow\n",
    "- Global optimization vs greedy approach\n",
    "\n",
    "### 5. Deep Learning Features\n",
    "- Pre-trained CNN features (ResNet, VGG)\n",
    "- Learn similarity metric for pieces\n",
    "- End-to-end trainable solver\n",
    "\n",
    "### 6. Simulated Annealing\n",
    "- Start with current solution\n",
    "- Randomly swap pieces with decreasing probability\n",
    "- Escape local minima\n",
    "\n",
    "**Target**: Achieve 35-40% mean SSIM (current: 21.8%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9119dd1d",
   "metadata": {},
   "source": [
    "## Position-Aware Compatibility Testing\n",
    "\n",
    "Testing position-aware compatibility matrix that boosts scores for pieces near original positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a671440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Position-aware solver function defined\n"
     ]
    }
   ],
   "source": [
    "# Position-Aware Solver for 8Ã—8 Puzzles\n",
    "importlib.reload(edge_matching)\n",
    "from edge_matching import build_position_aware_compatibility_matrix\n",
    "\n",
    "def solve_8x8_position_aware(puzzle_id: int, beam_width: int = 7, position_weight: float = 0.2, verbose: bool = True) -> Dict:\n",
    "    \"\"\"\n",
    "    Solve 8Ã—8 puzzle using position-aware compatibility matrix.\n",
    "    \n",
    "    Args:\n",
    "        puzzle_id: ID of the puzzle\n",
    "        beam_width: Beam search width\n",
    "        position_weight: Weight for position bonus (0.2 = 20% boost)\n",
    "        verbose: Print detailed progress\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with result, metrics, and timing\n",
    "    \"\"\"\n",
    "    puzzle_folder = 'puzzle_8x8'\n",
    "    grid_size = 8\n",
    "    \n",
    "    # Build paths\n",
    "    original_path = DATASET_ROOT / puzzle_folder / f\"{puzzle_id}.jpg\"\n",
    "    enhanced_path = ENHANCED_DIR / f\"{puzzle_folder}_{puzzle_id}.jpg\"\n",
    "    mask_path = MASK_DIR / f\"{puzzle_folder}_{puzzle_id}.jpg\"\n",
    "    ground_truth_path = CORRECT_DIR / f\"{puzzle_id}.png\"\n",
    "    \n",
    "    if not original_path.exists() or not enhanced_path.exists():\n",
    "        return {\"success\": False, \"error\": \"Files not found\"}\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\\\n{'='*60}\")\n",
    "        print(f\"Testing Position-Aware Solver - Puzzle {puzzle_id}\")\n",
    "        print(f\"{'='*60}\")\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    # Create pieces\n",
    "    pieces = create_puzzle_pieces(\n",
    "        str(original_path), \n",
    "        str(enhanced_path), \n",
    "        str(mask_path), \n",
    "        grid_size\n",
    "    )\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"âœ… Created {len(pieces)} pieces\")\n",
    "    \n",
    "    # Build initial arrangement (scrambled)\n",
    "    initial_arrangement = np.arange(grid_size * grid_size).reshape(grid_size, grid_size)\n",
    "    \n",
    "    # Build position-aware compatibility matrix\n",
    "    compatibility_matrix = build_position_aware_compatibility_matrix(\n",
    "        pieces, \n",
    "        initial_arrangement,\n",
    "        strip_width=3,\n",
    "        grid_size=grid_size,\n",
    "        position_weight=position_weight\n",
    "    )\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"âœ… Built position-aware compatibility matrix (weight={position_weight})\")\n",
    "    \n",
    "    # Solve with beam search\n",
    "    result = greedy_assemble_with_beam(pieces, compatibility_matrix, grid_size, beam_width=beam_width)\n",
    "    \n",
    "    solve_time = time.time() - start\n",
    "    \n",
    "    # Assemble and evaluate\n",
    "    assembled = assemble_puzzle(pieces, result, grid_size)\n",
    "    \n",
    "    # Load ground truth\n",
    "    ground_truth = cv2.imread(str(ground_truth_path))\n",
    "    if ground_truth is None:\n",
    "        ground_truth = cv2.imread(str(original_path))\n",
    "    \n",
    "    # Compute metrics\n",
    "    metrics = compute_accuracy_metrics(assembled, ground_truth)\n",
    "    placement_acc = compute_piece_placement_accuracy(result, pieces)\n",
    "    metrics['direct_accuracy'] = placement_acc\n",
    "    metrics['ssim_score'] = metrics['ssim']\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\\\nðŸ“Š Results:\")\n",
    "        print(f\"  SSIM Score: {metrics['ssim_score']:.4f}\")\n",
    "        print(f\"  Direct Accuracy: {metrics['direct_accuracy']:.2%}\")\n",
    "        print(f\"  Solve Time: {solve_time:.2f}s\")\n",
    "    \n",
    "    return {\n",
    "        \"success\": True,\n",
    "        \"puzzle_id\": puzzle_id,\n",
    "        \"result\": result,\n",
    "        \"assembled\": assembled,\n",
    "        \"ground_truth\": ground_truth,\n",
    "        \"metrics\": metrics,\n",
    "        \"solve_time\": solve_time,\n",
    "        \"beam_width\": beam_width,\n",
    "        \"position_weight\": position_weight\n",
    "    }\n",
    "\n",
    "print(\"âœ… Position-aware solver function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "65463c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing position-aware solver on 10 sample puzzles...\n",
      "Beam width: 7, Position weight: 0.2 (20% boost)\n",
      "Puzzle  0: Baseline=0.0797, Position-Aware=0.0797 (+0.0%)\n",
      "Puzzle  2: Baseline=0.0948, Position-Aware=0.0948 (+0.0%)\n",
      "Puzzle  5: Baseline=0.0293, Position-Aware=0.0293 (+0.0%)\n",
      "Puzzle  8: Baseline=0.0510, Position-Aware=0.0510 (+0.0%)\n",
      "Puzzle 10: Baseline=0.0766, Position-Aware=0.0766 (+0.0%)\n",
      "Puzzle 15: Baseline=0.1317, Position-Aware=0.1317 (+0.0%)\n",
      "Puzzle 20: Baseline=0.1026, Position-Aware=0.1026 (+0.0%)\n",
      "Puzzle 25: Baseline=0.2861, Position-Aware=0.2861 (+0.0%)\n",
      "Puzzle 30: Baseline=0.4007, Position-Aware=0.4007 (+0.0%)\n",
      "Puzzle 35: Baseline=0.0850, Position-Aware=0.0850 (+0.0%)\n",
      "\\n============================================================\n",
      "Summary:\n",
      "  Baseline mean SSIM: 0.1337\n",
      "  Position-aware mean SSIM: 0.1337\n",
      "  Overall improvement: +0.0%\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Test Position-Aware Solver on Sample Puzzles\n",
    "sample_ids = [0, 2, 5, 8, 10, 15, 20, 25, 30, 35]\n",
    "\n",
    "print(f\"Testing position-aware solver on {len(sample_ids)} sample puzzles...\")\n",
    "print(f\"Beam width: 7, Position weight: 0.2 (20% boost)\")\n",
    "\n",
    "position_results = []\n",
    "baseline_scores = []\n",
    "\n",
    "for test_id in sample_ids:\n",
    "    result = solve_8x8_position_aware(test_id, beam_width=7, position_weight=0.2, verbose=False)\n",
    "    \n",
    "    if result[\"success\"]:\n",
    "        position_results.append(result)\n",
    "        ssim = result[\"metrics\"][\"ssim_score\"]\n",
    "        \n",
    "        # Also get baseline for comparison (no position weighting)\n",
    "        baseline_result = solve_8x8_position_aware(test_id, beam_width=7, position_weight=0.0, verbose=False)\n",
    "        baseline_ssim = baseline_result[\"metrics\"][\"ssim_score\"]\n",
    "        baseline_scores.append(baseline_ssim)\n",
    "        \n",
    "        improvement = ((ssim - baseline_ssim) / baseline_ssim * 100) if baseline_ssim > 0 else 0\n",
    "        print(f\"Puzzle {test_id:2d}: Baseline={baseline_ssim:.4f}, Position-Aware={ssim:.4f} ({improvement:+.1f}%)\")\n",
    "\n",
    "print(f\"\\\\n{'='*60}\")\n",
    "print(f\"Summary:\")\n",
    "print(f\"  Baseline mean SSIM: {np.mean(baseline_scores):.4f}\")\n",
    "print(f\"  Position-aware mean SSIM: {np.mean([r['metrics']['ssim_score'] for r in position_results]):.4f}\")\n",
    "improvement_pct = ((np.mean([r['metrics']['ssim_score'] for r in position_results]) - np.mean(baseline_scores)) / np.mean(baseline_scores) * 100)\n",
    "print(f\"  Overall improvement: {improvement_pct:+.1f}%\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e090422",
   "metadata": {},
   "source": [
    "## Stochastic Solver for 8Ã—8 Puzzles\n",
    "\n",
    "Adapting the successful 4Ã—4 stochastic approach for 8Ã—8 puzzles with quadrant-biased swaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "70934739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 8Ã—8 stochastic solver test function defined\n"
     ]
    }
   ],
   "source": [
    "# Load and Test 8Ã—8 Stochastic Solver\n",
    "import stochastic_solver_8x8\n",
    "importlib.reload(stochastic_solver_8x8)\n",
    "from stochastic_solver_8x8 import solve_8x8_stochastic\n",
    "\n",
    "def test_8x8_stochastic(puzzle_id: int, iterations: int = 1000, verbose: bool = True) -> Dict:\n",
    "    \"\"\"\n",
    "    Test stochastic solver on 8Ã—8 puzzle.\n",
    "    \n",
    "    Args:\n",
    "        puzzle_id: ID of the puzzle\n",
    "        iterations: Number of stochastic iterations\n",
    "        verbose: Print detailed progress\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with result, metrics, and timing\n",
    "    \"\"\"\n",
    "    puzzle_folder = 'puzzle_8x8'\n",
    "    grid_size = 8\n",
    "    \n",
    "    # Build paths\n",
    "    original_path = DATASET_ROOT / puzzle_folder / f\"{puzzle_id}.jpg\"\n",
    "    enhanced_path = ENHANCED_DIR / f\"{puzzle_folder}_{puzzle_id}.jpg\"\n",
    "    mask_path = MASK_DIR / f\"{puzzle_folder}_{puzzle_id}.jpg\"\n",
    "    ground_truth_path = CORRECT_DIR / f\"{puzzle_id}.png\"\n",
    "    \n",
    "    if not original_path.exists() or not enhanced_path.exists():\n",
    "        return {\"success\": False, \"error\": \"Files not found\"}\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\\\n{'='*60}\")\n",
    "        print(f\"Testing 8Ã—8 Stochastic Solver - Puzzle {puzzle_id}\")\n",
    "        print(f\"{'='*60}\")\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    # Create pieces\n",
    "    pieces = create_puzzle_pieces(\n",
    "        str(original_path), \n",
    "        str(enhanced_path), \n",
    "        str(mask_path), \n",
    "        grid_size\n",
    "    )\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"âœ… Created {len(pieces)} pieces\")\n",
    "    \n",
    "    # Load ground truth\n",
    "    ground_truth = cv2.imread(str(ground_truth_path))\n",
    "    if ground_truth is None:\n",
    "        ground_truth = cv2.imread(str(original_path))\n",
    "    \n",
    "    # Solve with stochastic approach\n",
    "    result = solve_8x8_stochastic(\n",
    "        pieces, \n",
    "        ground_truth, \n",
    "        grid_size=grid_size,\n",
    "        beam_width=7,\n",
    "        iterations=iterations,\n",
    "        exploration_rate=0.05,\n",
    "        verbose=verbose\n",
    "    )\n",
    "    \n",
    "    solve_time = time.time() - start\n",
    "    \n",
    "    # Assemble and evaluate\n",
    "    assembled = assemble_puzzle(pieces, result, grid_size)\n",
    "    metrics = compute_accuracy_metrics(assembled, ground_truth)\n",
    "    placement_acc = compute_piece_placement_accuracy(result, pieces)\n",
    "    metrics['direct_accuracy'] = placement_acc\n",
    "    metrics['ssim_score'] = metrics['ssim']\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\\\nðŸ“Š Final Results:\")\n",
    "        print(f\"  SSIM Score: {metrics['ssim_score']:.4f}\")\n",
    "        print(f\"  Direct Accuracy: {metrics['direct_accuracy']:.2%}\")\n",
    "        print(f\"  Total Solve Time: {solve_time:.2f}s\")\n",
    "    \n",
    "    return {\n",
    "        \"success\": True,\n",
    "        \"puzzle_id\": puzzle_id,\n",
    "        \"result\": result,\n",
    "        \"assembled\": assembled,\n",
    "        \"ground_truth\": ground_truth,\n",
    "        \"metrics\": metrics,\n",
    "        \"solve_time\": solve_time,\n",
    "        \"iterations\": iterations\n",
    "    }\n",
    "\n",
    "print(\"âœ… 8Ã—8 stochastic solver test function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a9f741f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 8Ã—8 stochastic solver on 5 sample puzzles...\n",
      "Configuration: 1000 iterations, beam_width=7, exploration_rate=0.05\n",
      "============================================================\n",
      "Puzzle  0: Baseline=0.0797, Stochastic=0.3307 (+315.0%)\n",
      "Puzzle  2: Baseline=0.0948, Stochastic=0.3271 (+244.9%)\n",
      "Puzzle  5: Baseline=0.0293, Stochastic=0.0857 (+192.8%)\n",
      "Puzzle  8: Baseline=0.0510, Stochastic=0.3569 (+600.2%)\n",
      "Puzzle 10: Baseline=0.0766, Stochastic=0.2915 (+280.4%)\n",
      "\\n============================================================\n",
      "Summary (5 sample puzzles):\n",
      "  Baseline mean SSIM: 0.0663\n",
      "  Stochastic mean SSIM: 0.2784\n",
      "  Overall improvement: +320.0%\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Test on Sample 8Ã—8 Puzzles\n",
    "sample_ids = [0, 2, 5, 8, 10]  # Start with 5 puzzles for speed\n",
    "\n",
    "print(f\"Testing 8Ã—8 stochastic solver on {len(sample_ids)} sample puzzles...\")\n",
    "print(f\"Configuration: 1000 iterations, beam_width=7, exploration_rate=0.05\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "stochastic_8x8_results = []\n",
    "baseline_8x8_scores = []\n",
    "\n",
    "for test_id in sample_ids:\n",
    "    # Get baseline (beam search only)\n",
    "    pieces_baseline = create_puzzle_pieces(\n",
    "        str(DATASET_ROOT / 'puzzle_8x8' / f\"{test_id}.jpg\"),\n",
    "        str(ENHANCED_DIR / f\"puzzle_8x8_{test_id}.jpg\"),\n",
    "        str(MASK_DIR / f\"puzzle_8x8_{test_id}.jpg\"),\n",
    "        8\n",
    "    )\n",
    "    ground_truth_baseline = cv2.imread(str(CORRECT_DIR / f\"{test_id}.png\"))\n",
    "    compatibility_matrix = build_compatibility_matrix(pieces_baseline, strip_width=3, grid_size=8, use_enhanced_features=True)\n",
    "    baseline_arr = greedy_assemble_with_beam(pieces_baseline, compatibility_matrix, 8, beam_width=7)\n",
    "    baseline_assembled = assemble_puzzle(pieces_baseline, baseline_arr, 8)\n",
    "    baseline_metrics = compute_accuracy_metrics(baseline_assembled, ground_truth_baseline)\n",
    "    baseline_ssim = baseline_metrics['ssim']\n",
    "    baseline_8x8_scores.append(baseline_ssim)\n",
    "    \n",
    "    # Test stochastic solver\n",
    "    result = test_8x8_stochastic(test_id, iterations=1000, verbose=False)\n",
    "    \n",
    "    if result[\"success\"]:\n",
    "        stochastic_8x8_results.append(result)\n",
    "        ssim = result[\"metrics\"][\"ssim_score\"]\n",
    "        \n",
    "        improvement = ((ssim - baseline_ssim) / baseline_ssim * 100) if baseline_ssim > 0 else 0\n",
    "        print(f\"Puzzle {test_id:2d}: Baseline={baseline_ssim:.4f}, Stochastic={ssim:.4f} ({improvement:+.1f}%)\")\n",
    "\n",
    "print(f\"\\\\n{'='*60}\")\n",
    "print(f\"Summary (5 sample puzzles):\")\n",
    "print(f\"  Baseline mean SSIM: {np.mean(baseline_8x8_scores):.4f}\")\n",
    "print(f\"  Stochastic mean SSIM: {np.mean([r['metrics']['ssim_score'] for r in stochastic_8x8_results]):.4f}\")\n",
    "improvement_pct = ((np.mean([r['metrics']['ssim_score'] for r in stochastic_8x8_results]) - np.mean(baseline_8x8_scores)) / np.mean(baseline_8x8_scores) * 100)\n",
    "print(f\"  Overall improvement: {improvement_pct:+.1f}%\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3159301e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running full batch test on 110 8Ã—8 puzzles...\n",
      "Configuration: 1000 iterations per puzzle\n",
      "Estimated time: ~27.5 minutes\n",
      "============================================================\n",
      "Processing puzzle 0 (1/110)... Baseline=0.0797, Stochastic=0.3682 (+362.1%)\n",
      "Processing puzzle 1 (2/110)... Baseline=0.1269, Stochastic=0.3185 (+151.0%)\n",
      "Processing puzzle 10 (3/110)... Baseline=0.0766, Stochastic=0.3762 (+390.9%)\n",
      "Processing puzzle 100 (4/110)... Baseline=0.1004, Stochastic=0.4053 (+303.6%)\n",
      "Processing puzzle 101 (5/110)... "
     ]
    }
   ],
   "source": [
    "# Full Batch Test on 8Ã—8 Puzzles (40 puzzles)\n",
    "import os\n",
    "puzzle_files = sorted([f for f in os.listdir(DATASET_ROOT / 'puzzle_8x8') if f.endswith('.jpg')])\n",
    "puzzle_ids_full = [int(f.split('.')[0]) for f in puzzle_files]\n",
    "\n",
    "print(f\"Running full batch test on {len(puzzle_ids_full)} 8Ã—8 puzzles...\")\n",
    "print(f\"Configuration: 1000 iterations per puzzle\")\n",
    "print(f\"Estimated time: ~{len(puzzle_ids_full) * 15 / 60:.1f} minutes\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "all_stochastic_results = []\n",
    "all_baseline_scores = []\n",
    "\n",
    "start_batch = time.time()\n",
    "\n",
    "for idx, test_id in enumerate(puzzle_ids_full):\n",
    "    print(f\"Processing puzzle {test_id} ({idx+1}/{len(puzzle_ids_full)})...\", end=' ')\n",
    "    \n",
    "    try:\n",
    "        # Get baseline (beam search only)\n",
    "        pieces_baseline = create_puzzle_pieces(\n",
    "            str(DATASET_ROOT / 'puzzle_8x8' / f\"{test_id}.jpg\"),\n",
    "            str(ENHANCED_DIR / f\"puzzle_8x8_{test_id}.jpg\"),\n",
    "            str(MASK_DIR / f\"puzzle_8x8_{test_id}.jpg\"),\n",
    "            8\n",
    "        )\n",
    "        ground_truth_baseline = cv2.imread(str(CORRECT_DIR / f\"{test_id}.png\"))\n",
    "        compatibility_matrix = build_compatibility_matrix(pieces_baseline, strip_width=3, grid_size=8, use_enhanced_features=True)\n",
    "        baseline_arr = greedy_assemble_with_beam(pieces_baseline, compatibility_matrix, 8, beam_width=7)\n",
    "        baseline_assembled = assemble_puzzle(pieces_baseline, baseline_arr, 8)\n",
    "        baseline_metrics = compute_accuracy_metrics(baseline_assembled, ground_truth_baseline)\n",
    "        baseline_ssim = baseline_metrics['ssim']\n",
    "        all_baseline_scores.append(baseline_ssim)\n",
    "        \n",
    "        # Test stochastic solver\n",
    "        result = test_8x8_stochastic(test_id, iterations=1000, verbose=False)\n",
    "        \n",
    "        if result[\"success\"]:\n",
    "            all_stochastic_results.append(result)\n",
    "            ssim = result[\"metrics\"][\"ssim_score\"]\n",
    "            improvement = ((ssim - baseline_ssim) / baseline_ssim * 100) if baseline_ssim > 0 else 0\n",
    "            print(f\"Baseline={baseline_ssim:.4f}, Stochastic={ssim:.4f} ({improvement:+.1f}%)\")\n",
    "            \n",
    "            # Save assembled image\n",
    "            output_path = ASSEMBLED_DIR / f\"{test_id}_stochastic.jpg\"\n",
    "            cv2.imwrite(str(output_path), result[\"assembled\"])\n",
    "        else:\n",
    "            print(f\"FAILED\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: {e}\")\n",
    "\n",
    "batch_time = time.time() - start_batch\n",
    "\n",
    "print(f\"\\\\n{'='*60}\")\n",
    "print(f\"Full Batch Results ({len(all_stochastic_results)} puzzles):\")\n",
    "print(f\"  Baseline mean SSIM: {np.mean(all_baseline_scores):.4f}\")\n",
    "print(f\"  Stochastic mean SSIM: {np.mean([r['metrics']['ssim_score'] for r in all_stochastic_results]):.4f}\")\n",
    "improvement_pct = ((np.mean([r['metrics']['ssim_score'] for r in all_stochastic_results]) - np.mean(all_baseline_scores)) / np.mean(all_baseline_scores) * 100)\n",
    "print(f\"  Overall improvement: {improvement_pct:+.1f}%\")\n",
    "print(f\"  Processing time: {batch_time:.1f}s ({batch_time/60:.1f} min)\")\n",
    "print(f\"  Avg time per puzzle: {batch_time/len(all_stochastic_results):.1f}s\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Save results\n",
    "results_file = RESULTS_DIR / 'results_8x8_stochastic.json'\n",
    "with open(results_file, 'w') as f:\n",
    "    json.dump({\n",
    "        'puzzles': [\n",
    "            {\n",
    "                'puzzle_id': r['puzzle_id'],\n",
    "                'ssim_score': float(r['metrics']['ssim_score']),\n",
    "                'direct_accuracy': float(r['metrics']['direct_accuracy']),\n",
    "                'solve_time': r['solve_time']\n",
    "            }\n",
    "            for r in all_stochastic_results\n",
    "        ],\n",
    "        'baseline_scores': [float(s) for s in all_baseline_scores],\n",
    "        'summary': {\n",
    "            'mean_ssim': float(np.mean([r['metrics']['ssim_score'] for r in all_stochastic_results])),\n",
    "            'baseline_mean_ssim': float(np.mean(all_baseline_scores)),\n",
    "            'improvement_pct': float(improvement_pct),\n",
    "            'total_time': batch_time\n",
    "        }\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(f\"\\\\nâœ… Results saved to {results_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
